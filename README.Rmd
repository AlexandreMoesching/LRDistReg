---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "80%"
)
```

# LRDistReg

<!-- badges: start -->
<!-- badges: end -->

Consider bivariate observations $(X_1, Y_1), \ldots , (X_n, Y_n) \in \mathbb{R}\times\mathbb{R}$ with unknown conditional distributions $Q_x$ of $Y$, given that $X = x$. The goal is to estimate these distributions under the sole assumption that $Q_x$ is isotonic in $x$ with respect to likelihood ratio order. Precisely, for $x_1 < x_2$, we say that $Q_{x_1}$ is smaller $Q_{x_2}$ in likelihood ratio order if both distributions have respective densities $g_{x_1}$ and $g_{x_2}$ with respect to some dominating measure such that $g_{x_2} / g_{x_1}$ is isotonic on the set $\{g_{x_1} + g_{x_2} > 0\}$.

We follow an empirical likelihood approach to estimate the unknown family
of distributions $(Q_x)_x$. After reparametrization, we show that the problem of maximizing the (empirical) likelihood under likelihood ratio order constraint yields a finite-dimensional convex optimization problem with linear inequality
constraints. We devise an algorithm which makes use of a quasi-Newton
approach, with new search directions obtained via multiple isotonic weighted least squares regression. Detailed derivations are given in [Moesching and Duembgen (2022)](https://arxiv.org/abs/2007.11521).

Most functions are implemented both in `R` and `C++` in order to have an easy to read implementation as well as a fast one. The main functions are `dist_reg_R()` and `dist_reg_C()` which, given covariates `X` and responses `Y`, estimate the unknown family of distributions $(Q_x)_x$ for $x\in\{X_1,\ldots,X_n\}$ in `R` and in `C++`. Optional arguments include sample weights `W`, a threshold `delta0` for the stopping criteria, a set of other covariates `x0` on which to extend the original fit via linear interpolation, and a Boolean `ST` determining whether or not to estimate distributions under usual stochastic order constraint.

The package also includes the `growthdata` dataset. It contains the public release data from three NHANES and two NHES surveys used in the development of the 2000 CDC growth charts for the United States. The study was conducted in the US between 1963 and 1991. The original data can be found here [www.cdc.gov](https://wwwn.cdc.gov/nchs/nhanes/nhanes3/DataFiles.aspx).

This document shows basic usage of the package.

## PART 0: Installation

You can install and load the development version of LRDistReg from [GitHub](https://github.com/AlexandreMoesching/LRDistReg) by running the following lines (after having uncommented them):

```{r install_and_load}
# install.packages("devtools")
# devtools::install_github("AlexandreMoesching/LRDistReg")
library(LRDistReg)
```

## PART 1: True parametric model

The present demo uses a gamma family of distributions $(Q_x)_{x\in \mathfrak{X}}$. More precisely
$Q_x := \mathrm{Gamma}\bigl(a(x), b(x)\bigr)$ for all $x \in \mathfrak{X} := [1,4]$, with some shape $a: \mathfrak{X} \to (0,\infty)$ and scale $b: \mathfrak{X} \to (0,\infty)$.

```{r true_family_of_distributions}
rm(list = ls())
set.seed(1)
a <- function(x) 2 + (x+1)^2
b <- function(x) 1 - exp(-10*x)
r.cond.dist <- function(x) rgamma(1, shape = a(x), scale = b(x))
p.cond.dist <- function(x, y) pgamma(y, shape = a(x), scale = b(x))
d.cond.dist <- function(x, y) dgamma(y, shape = a(x), scale = b(x))
q.cond.dist <- function(x, alpha) qgamma(alpha, shape = a(x), scale = b(x))
```

The following plot displays the true family of distributions. For each $(x,y)$ in a certain rectangle, the value of $(\mathrm{d}Q_x/\mathrm{d}y)(y)$ is given by the color scale.

```{r visual_output, echo = FALSE}
xx <- seq(1, 4, length.out = 2e2)
yy <- seq(q.cond.dist(1, 0.05), q.cond.dist(4, 0.95), length.out = 2e2)
lattice::levelplot(outer(xx, yy, FUN = "d.cond.dist"), 
                   nlevels = 1e2, aspect = "fill",
                   col.regions = hcl.colors(1e2),
                   row.values = xx, column.values = yy,
                   xlab = expression(italic(x)), ylab = expression(italic(y)),
                   xlim = range(xx), ylim = range(yy))
```

## PART 2: Small data example

We start with a basic example: Draw $n = 30$ observation pairs $(X_1,Y_1),(X_2,Y_2),...,(X_n,Y_n)$ with covariates in a set $\mathfrak{X}_o := 1 + 3*\{1,2,...,\ell_o\}/\ell_o$, for $\ell_o = 10$.

```{r basic_parameters}
# We define a function to generate data
gen_data <- function(n, l0, round = FALSE) {
  X <- sort(sample(1 + (1:l0) / l0 * 3, size = n, replace = TRUE))
  Y <- rep(0, n)
  for (i in 1:n) Y[i] <- r.cond.dist(X[i])
  if (round) {
    Y <- round(Y, 1) # Should create some ties
  }
  return(list(X = X, Y = Y))
}

n <- 30; l0 <- 10
data <- gen_data(n, l0)
```

We estimate the family of distributions using the function `dist_reg_R()` with default options.

```{r first_fit}
res <- dist_reg_R(data$X, data$Y)
plotD(res$par, indices = FALSE)
```

The design of the experiment should be shown. The color of a pair $(x,y)$ is equal to the number of observations at that location, plus $1$. In consequence, black points contain no observations, red points contain one observation pair, green points contain two observation pairs, etc.

The family of distributions is estimated at each points of this grid. The estimated conditional distribution functions are given by `res$CDF_LR`, an $\ell$-by-$m$ matrix.

## PART 3: Comparison between Likelihood-Ratio ordering, usual STochastic ordering and the EMPirical for a larger dataset

This time we obtain the fit using a self-specified value of the precision parameter $\delta_o$. The option `ST = TRUE` will compute empirical distributions as well as estimates under usual stochastic order.

```{r options_and_data_large}
n <- 1e3; l0 <- 1e2
data <- gen_data(n, l0, TRUE)
res <- dist_reg_R(data$X, data$Y, delta0 = 1e-2, ST = TRUE)
x <- res$par$x                       # Unique covariates 
y <- res$par$y                       # Unique responses
l <- res$par$l                       # Number of unique covariates
m <- res$par$m                       # Number of unique responses
CDF_LR <- res$CDF_LR                 # LR-ordered estimated CDFs
CDF_ST <- res$CDF_ST                 # ST-ordered estimated CDFs
CDF_EMP <- res$CDF_EMP               # Empirical CDFs
CDF_TRUE <- outer(x, y, p.cond.dist) # True CDFs
```

The following plot displays the true CDF as well as its estimators for two values of $x$: One middle covariate ($x = 2.5$) and one boundary covariate ($x = 4$).

```{r plot_fit, echo = FALSE}
plot(0, type = "n",
     xlab = expression(italic(y)), ylab = expression(italic(G[x](y))),
     xlim = range(y), ylim = c(0,1), lwd = 2)
for (xj in c(2.5, 4)) {
  j <- which(xj == x)
  lines(y, CDF_TRUE[j,], lwd = 2)
  lines(y, CDF_LR[j,], col = 2, lwd = 2)
  lines(y, CDF_ST[j,], col = 4, lwd = 2)
  lines(y, CDF_EMP[j,], lty = 2)
  legend("topleft", legend = c("True", "LR", "ST", "EMP"),
         col = c(1, 2, 4, 1), lty = c(rep(1, 3),2), lwd = c(rep(2, 3), 1))
}
```

The LR-estimator is in general smoother than the ST-estimator. In this specific example, the LR-estimator is also closer to the true distribution than the ST-estimator.

## PART 4: Growth data and interpolation feature

We take a sample of $n=2000$ girls between $2$ and $16$ years old from the `growthdata`, estimate CDFs (this time using the C++ function) for all years and months between $2$ and $16$ (using the interpolation feature `x0`) and produce $\beta$-quantile curves (taut strings between each pair of lower and upper $\beta$-quantile curves).

```{r growth_data}
data <- growthdata[(growthdata$sex == 2) &
                     (2 * 12 <= growthdata$age.months) & 
                     (growthdata$age.months <= 16 * 12) &
                     !is.na(growthdata$weight), c("age.months", "weight")]
n_full <- nrow(data)
x0 <- sort(unique(data$age.months)); l0 <- length(x0)

n <- 2e3
ii <- sample(1:n_full, n, replace = FALSE)
X <- data$age.months[ii]; Y <- data$weight[ii]

res <- dist_reg_C(X, Y, rep(1, n), 1e-2, ST = FALSE, x0 = x0)
CDF_LR <- res$CDF_LR
par <- res$par
x <- par$x
y <- par$y

beta.seq <- c(0.10, 0.25, 0.5, 0.75, 0.90); beta.n <- length(beta.seq)

# Compute lower and upper quantile curves, and then a taut string
QLR <- matrix(0, nrow = l0, ncol = beta.n)
for (s in seq_along(beta.seq)) {
  QL <- QU <- rep(0, l0)
  for (j in 1:l0) {
    QL[j] <- y[min(which(CDF_LR[j,] >= beta.seq[s]))]
    QU[j] <- y[min(which(CDF_LR[j,] >  beta.seq[s]))]
  }
  QLR[, s] <- QL
  if (any(QL[-c(1, l0)] != QU[-c(1, l0)])) {
    QL[1] <- QU[1]; QU[l0] <- QL[l0]
    QLR[, s] <- taut.string(QL[, s], QU[, s], x)$Y
  }
}

plot(data[ii,], pch = 16, cex = 0.3, xaxt = "n", log = "y",
     ylim = range(data$weight[ii]) * c(0.9, 1.1),
     xlab = "Age [years]", ylab = "Weight [kg]")
axis(1, at = 12 * 2:16, labels = 2:16)
for (s in seq_along(beta.seq)) {
  lines(x0, QLR[, s], lwd = 2.5)
}
```
